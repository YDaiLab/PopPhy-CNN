{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3' \n",
    "from os.path import abspath\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from utils.generate_network import generate_network\n",
    "from utils.prepare_data import prepare_data\n",
    "from utils.popphy_io import get_config, save_params, load_params\n",
    "from utils.popphy_io import get_stat, get_stat_dict\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from models.PopPhy import PopPhyCNN\n",
    "from models.CNN1D import CNN1D\n",
    "from models.MLPNN import MLPNN\n",
    "from models.RF import RF\n",
    "from models.SVM import SVM\n",
    "from models.LASSO import LASSO\n",
    "import warnings\n",
    "from datetime import datetime\n",
    "import json\n",
    "from cyjupyter import Cytoscape\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "### Reading Configuration\n",
    "The configuration file (config.py) contains all relevant parameters that can be set by the user. It is loaded and some parameters are stored in variables. The dataset should be found in _../data/_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = get_config()\n",
    "filt_thresh = config.get('Evaluation', 'FilterThresh')\n",
    "dataset = config.get('Evaluation', 'DataSet')\n",
    "num_runs = int(config.get('Evaluation', 'NumberRuns'))\n",
    "num_test = int(config.get('Evaluation', 'NumberTestSplits'))\n",
    "path = \"../data/\" + dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Result Directory\n",
    "The notebook results will be saved in _../results/notebook_results/_ under a directory with the shared name as the dataset. The directories are created if they do not exist."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_dir = \"../results/notebook_results/\" + dataset\n",
    "\n",
    "try:\n",
    "    os.makedirs(results_dir)\n",
    "except OSError:\n",
    "    print (\"Creation of the directory %s failed\" % results_dir)\n",
    "else:\n",
    "    print (\"Successfully created the directory %s\" % results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data\n",
    "The configuration file is passed to _prepare_data()_ to contruct the taxonomic tree from the data. Populated taxonomic trees in matrix format are returned as well as their respective original feature vectors and tree vectors, with samples in the same order. Labels are converted to one-hot encoding for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_maps, raw_x, tree_x, raw_features, tree_features, labels, label_set, g, feature_df = prepare_data(path, config)\n",
    "\n",
    "num_class = len(np.unique(labels))\n",
    "if num_class == 2:\n",
    "    metric = \"AUC\"\n",
    "else:\n",
    "    metric = \"MCC\"\n",
    "\n",
    "seed = np.random.randint(100)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(my_maps)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(raw_x)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(tree_x)\n",
    "np.random.seed(seed)\n",
    "np.random.shuffle(labels)\n",
    "\n",
    "n_values = np.max(labels) + 1\n",
    "labels_oh = np.eye(n_values)[labels]\n",
    "\n",
    "tree_row = my_maps.shape[1]\n",
    "tree_col = my_maps.shape[2]\n",
    "\n",
    "print(\"There are %d classes...%s\" % (num_class, \", \".join(label_set)))\n",
    "cv_list = [\"Run_\" + str(x) + \"_CV_\" + str(y) for x in range(num_runs) for y in range(num_test)]\n",
    "seeds = np.random.randint(1000, size=num_runs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PopPhy-CNN Cross Validation\n",
    "\n",
    "A dataframe for saving scores during the cross-validation is set up. Training is done using stratified cross-validation. Data is log transformed and then a MinMax transformation is learned on the training set and applied to the held out set. This allows features to share similar scales while still remaining positive, which is important for the feature evaluation method. Class weights are learned based on the class proportion in the training set. These weights are used for constructing a weighted loss function. PopPhy-CNN models are trained and AUC, MCC, Precision, Recall, and F1 Score are saved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise (GaussianNois (None, 10, 179, 1)        0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 8, 170, 32)        992       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 4, 85, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 10880)             0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 10880)             0         \n",
      "_________________________________________________________________\n",
      "fc_0 (Dense)                 (None, 32)                348192    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 349,250\n",
      "Trainable params: 349,250\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " Run\tFold\tAUC\n",
      "# 0\t0\t0.972\n",
      "# 0\t1\t0.778\n",
      "# 0\t2\t0.979\n",
      "# 0\t3\t0.910\n",
      "# 0\t4\t0.833\n",
      "# 0\t5\t0.985\n",
      "# 0\t6\t0.871\n",
      "# 0\t7\t1.000\n",
      "# 0\t8\t0.926\n",
      "# 0\t9\t0.851\n"
     ]
    }
   ],
   "source": [
    "popphy_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "\n",
    "feature_scores = {}\n",
    "\n",
    "for l in label_set:\n",
    "    feature_scores[l] = pd.DataFrame(index=tree_features)\n",
    "run = 0\n",
    "for seed in seeds:\n",
    "    skf = StratifiedKFold(n_splits=num_test, shuffle=True, random_state=seed)\n",
    "    fold = 0\n",
    "    for train_index, test_index in skf.split(my_maps, labels):\n",
    "        train_x, test_x = my_maps[train_index,:,:], my_maps[test_index,:,:]\n",
    "        train_y, test_y = labels_oh[train_index,:], labels_oh[test_index,:]\n",
    "        \n",
    "        train_x = np.log(train_x + 1)\n",
    "        test_x = np.log(test_x + 1)\n",
    "        \n",
    "        c_prob = [0] * len(np.unique(labels))\n",
    "        train_weights = []\n",
    "\n",
    "        for l in np.unique(labels):\n",
    "            a = float(len(labels))\n",
    "            b = 2.0 * float((np.sum(labels==l)))\n",
    "            c_prob[int(l)] = a/b\n",
    "\n",
    "        c_prob = np.array(c_prob).reshape(-1)\n",
    "\n",
    "        for l in np.argmax(train_y, 1):\n",
    "            train_weights.append(c_prob[int(l)])\n",
    "        train_weights = np.array(train_weights)\n",
    "        \n",
    "        scaler = MinMaxScaler().fit(train_x.reshape(-1, tree_row * tree_col))\n",
    "        train_x = np.clip(scaler.transform(train_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "        test_x = np.clip(scaler.transform(test_x.reshape(-1, tree_row * tree_col)), 0, 1).reshape(-1, tree_row, tree_col)\n",
    "\n",
    "        train = [train_x, train_y]\n",
    "        test = [test_x, test_y]\n",
    "\n",
    "        popphy_model = PopPhyCNN((tree_row, tree_col), num_class, config)\n",
    "\n",
    "        if fold + run == 0:\n",
    "            print(popphy_model.model.summary())\n",
    "            print(\"\\n\\n Run\\tFold\\t%s\" % (metric))\n",
    "\n",
    "        popphy_model.train(train, train_weights)\n",
    "        preds, stats = popphy_model.test(test)\n",
    "        if num_class == 2:\n",
    "                popphy_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stats[\"AUC\"]\n",
    "        popphy_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stats[\"MCC\"]\n",
    "        popphy_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stats[\"Precision\"]\n",
    "        popphy_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stats[\"Recall\"]\n",
    "        popphy_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=stats[\"F1\"]\n",
    "\n",
    "        if metric == \"AUC\":\n",
    "                print(\"# %d\\t%d\\t%.3f\" % (run, fold, stats[\"AUC\"]))\n",
    "        if metric == \"MCC\":\n",
    "                print(\"# %d\\t%d\\t%.3f\\t\" % (run, fold, stats[\"MCC\"]))\n",
    "\n",
    "        scores = popphy_model.get_feature_scores(train, g, label_set, tree_features, config)\n",
    "        for l in range(len(label_set)):\n",
    "                score_list = scores[:,l]\n",
    "                lab = label_set[l]\n",
    "                feature_scores[lab][\"Run_\" + str(run) + \"_CV_\" + str(fold)] = score_list\n",
    "\n",
    "\n",
    "        popphy_model.destroy()\n",
    "        fold += 1\n",
    "    run += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving Metrics\n",
    "\n",
    "Evaluation metrics for each partition of each cross-validation run and the mean metrics are saved in the results directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run_0_CV_0</th>\n",
       "      <th>Run_0_CV_1</th>\n",
       "      <th>Run_0_CV_2</th>\n",
       "      <th>Run_0_CV_3</th>\n",
       "      <th>Run_0_CV_4</th>\n",
       "      <th>Run_0_CV_5</th>\n",
       "      <th>Run_0_CV_6</th>\n",
       "      <th>Run_0_CV_7</th>\n",
       "      <th>Run_0_CV_8</th>\n",
       "      <th>Run_0_CV_9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.972222</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.909722</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.984848</td>\n",
       "      <td>0.871212</td>\n",
       "      <td>1</td>\n",
       "      <td>0.92562</td>\n",
       "      <td>0.85124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.707107</td>\n",
       "      <td>0.338062</td>\n",
       "      <td>0.774597</td>\n",
       "      <td>0.53033</td>\n",
       "      <td>0.516459</td>\n",
       "      <td>0.825758</td>\n",
       "      <td>0.568182</td>\n",
       "      <td>1</td>\n",
       "      <td>0.730297</td>\n",
       "      <td>0.547723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.875</td>\n",
       "      <td>0.671429</td>\n",
       "      <td>0.9</td>\n",
       "      <td>0.78125</td>\n",
       "      <td>0.775362</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.785573</td>\n",
       "      <td>1</td>\n",
       "      <td>0.866667</td>\n",
       "      <td>0.775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.875</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.73913</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.772727</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.828571</td>\n",
       "      <td>0.664336</td>\n",
       "      <td>0.873016</td>\n",
       "      <td>0.742857</td>\n",
       "      <td>0.73311</td>\n",
       "      <td>0.913043</td>\n",
       "      <td>0.782609</td>\n",
       "      <td>1</td>\n",
       "      <td>0.863354</td>\n",
       "      <td>0.772257</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Run_0_CV_0 Run_0_CV_1 Run_0_CV_2 Run_0_CV_3 Run_0_CV_4 Run_0_CV_5  \\\n",
       "AUC         0.972222   0.777778   0.979167   0.909722   0.833333   0.984848   \n",
       "MCC         0.707107   0.338062   0.774597    0.53033   0.516459   0.825758   \n",
       "Precision      0.875   0.671429        0.9    0.78125   0.775362   0.913043   \n",
       "Recall      0.833333   0.666667      0.875       0.75    0.73913   0.913043   \n",
       "F1          0.828571   0.664336   0.873016   0.742857    0.73311   0.913043   \n",
       "\n",
       "          Run_0_CV_6 Run_0_CV_7 Run_0_CV_8 Run_0_CV_9  \n",
       "AUC         0.871212          1    0.92562    0.85124  \n",
       "MCC         0.568182          1   0.730297   0.547723  \n",
       "Precision   0.785573          1   0.866667      0.775  \n",
       "Recall      0.782609          1   0.863636   0.772727  \n",
       "F1          0.782609          1   0.863354   0.772257  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popphy_stat_df.to_csv(results_dir + \"/popphy_evaluation.csv\")\n",
    "popphy_stat_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AUC          0.910514\n",
       "MCC          0.653851\n",
       "Precision    0.834332\n",
       "Recall       0.819615\n",
       "F1           0.817315\n",
       "dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "popphy_stat_df.mean(1).to_csv(results_dir + \"/popphy_mean_evaluation.csv\")\n",
    "popphy_stat_df.mean(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Network Construction\n",
    "\n",
    "The _generate_network()_ function returns a network dictionary and a dataframe of feature scores from the tree. The scores are saved as a CSV file. The _network_ object can be used in Cytoscapes Jupyter Notebook API. To visualize the network using the desktop application for Cystoscape, the network is converted to JSON and saved in the result directory. This file can be imported into the Cytoscape's desktop application. An XML style file is provided in the _cytoscape_style_ directory which can also be loaded to visualize the tree based on a score gradient."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "network, tree_scores = generate_network(g, feature_scores, label_set)\n",
    "\n",
    "with open(results_dir + '/network.json', 'w') as json_file:\n",
    "    json.dump(network, json_file, sort_keys=True, indent=4, separators=(',', ': '))\n",
    "tree_scores.to_csv(results_dir + '/feature_scores.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final PopPhy-CNN Model\n",
    "\n",
    "After evaluation, a full model is trained using the entire dataset. This model can be used for future predictions and is saved in the results directory as an H5 file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_x = MinMaxScaler().fit_transform(my_maps.reshape(-1, tree_row * tree_col)).reshape(-1,tree_row, tree_col)\n",
    "train = [final_x, labels_oh]\n",
    "\n",
    "train_weights = []\n",
    "\n",
    "for l in np.unique(labels):\n",
    "    a = float(len(labels))\n",
    "    b = 2.0 * float((np.sum(labels==l)))\n",
    "    c_prob[int(l)] = a/b\n",
    "\n",
    "c_prob = np.array(c_prob).reshape(-1)\n",
    "\n",
    "for l in np.argmax(labels_oh, 1):\n",
    "    train_weights.append(c_prob[int(l)])\n",
    "train_weights = np.array(train_weights)\n",
    "popphy_model = PopPhyCNN((tree_row, tree_col), num_class, config)\n",
    "popphy_model.train(train, train_weights)\n",
    "popphy_model.model.save(results_dir + '/PopPhy-CNN.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Benchmarking\n",
    "\n",
    "Benchmarking is performed using random forest (RF), support vector machines (SVM), LASSO, MLPNN, and 1D-CNN models. The same partitions are used that were used in the cross validation and the same metrics are evaluated. We evaluate both the original features, as well as all the tree features that have been vectorized. Metrics for each model are saved in their independent files. Mean metrics for each model are also saved in a single file.\n",
    "\n",
    "### Original Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-1D\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise (GaussianNois (None, 1, 269, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 1, 260, 32)        352       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 130, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 1, 121, 32)        10272     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 60, 32)         0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 1920)              0         \n",
      "_________________________________________________________________\n",
      "fc_0 (Dense)                 (None, 32)                61472     \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 73,218\n",
      "Trainable params: 73,218\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "MLPNN\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_1 (GaussianNo (None, 269)               0         \n",
      "_________________________________________________________________\n",
      "fc_0 (Dense)                 (None, 32)                8640      \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 9,762\n",
      "Trainable params: 9,762\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " Run\tFold\tRF AUC\t\tSVM AUC\t\tLASSO AUC\tMLPNN AUC\tCNN-1D AUC\n",
      "# 0\t0\t1.000\t\t0.986\t\t0.889\t\t0.958\t\t1.000\n",
      "# 0\t1\t0.958\t\t0.931\t\t0.806\t\t0.875\t\t0.896\n",
      "# 0\t2\t0.944\t\t0.938\t\t0.910\t\t0.917\t\t0.917\n",
      "# 0\t3\t0.903\t\t0.889\t\t0.896\t\t0.889\t\t0.764\n",
      "# 0\t4\t0.924\t\t0.924\t\t0.886\t\t0.917\t\t0.833\n",
      "# 0\t5\t0.962\t\t0.992\t\t0.939\t\t1.000\t\t0.992\n",
      "# 0\t6\t0.909\t\t0.932\t\t0.955\t\t0.947\t\t0.780\n",
      "# 0\t7\t1.000\t\t1.000\t\t0.985\t\t0.992\t\t1.000\n",
      "# 0\t8\t0.880\t\t0.926\t\t0.926\t\t0.934\t\t0.909\n",
      "# 0\t9\t0.876\t\t0.876\t\t0.826\t\t0.810\t\t0.901\n"
     ]
    }
   ],
   "source": [
    "cnn1d_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "mlpnn_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "rf_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "svm_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "lasso_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "\n",
    "run = 0\n",
    "for seed in seeds:\n",
    "    skf = StratifiedKFold(n_splits=num_test, shuffle=True, random_state=seed)\n",
    "    fold = 0\n",
    "    for train_index, test_index in skf.split(my_maps, labels):\n",
    "        train_x, test_x = raw_x[train_index,:], raw_x[test_index,:]\n",
    "        train_y_oh, test_y_oh = labels_oh[train_index,:], labels_oh[test_index,:]\n",
    "        train_y, test_y = labels[train_index], labels[test_index]\n",
    "        \n",
    "        train_x = np.log(train_x + 1)\n",
    "        test_x = np.log(test_x + 1)\n",
    "        \n",
    "        c_prob = [0] * len(np.unique(labels))\n",
    "        train_weights = []\n",
    "\n",
    "        for l in np.unique(labels):\n",
    "            a = float(len(labels))\n",
    "            b = 2.0 * float((np.sum(labels==l)))\n",
    "            c_prob[int(l)] = a/b\n",
    "\n",
    "        c_prob = np.array(c_prob).reshape(-1)\n",
    "\n",
    "        for l in np.argmax(train_y_oh, 1):\n",
    "            train_weights.append(c_prob[int(l)])\n",
    "        train_weights = np.array(train_weights)\n",
    "        \n",
    "        scaler = MinMaxScaler().fit(train_x)\n",
    "        train_x = np.clip(scaler.transform(train_x), 0, 1)\n",
    "        test_x = np.clip(scaler.transform(test_x), 0, 1) \n",
    "\n",
    "        train_oh = [train_x, train_y_oh]\n",
    "        test_oh = [test_x, test_y_oh]\n",
    "\n",
    "        train = [train_x, train_y]\n",
    "        test = [test_x, test_y]\n",
    "        \n",
    "        cnn1D_model = CNN1D(train_x.shape[1], num_class, config)\n",
    "        mlpnn_model = MLPNN(train_x.shape[1], num_class, config)\n",
    "        rf_model = RF(config)\n",
    "        svm_model = SVM(config, label_set)\n",
    "        lasso_model = LASSO(config, label_set)\n",
    "        \n",
    "        if fold + run == 0:\n",
    "            print(\"CNN-1D\")\n",
    "            print(cnn1D_model.model.summary())\n",
    "            print(\"\\n\\nMLPNN\")\n",
    "            print(mlpnn_model.model.summary())\n",
    "            print(\"\\n\\n Run\\tFold\\tRF %s\\t\\tSVM %s\\t\\tLASSO %s\\tMLPNN %s\\tCNN-1D %s\" % (metric, metric, \n",
    "                                                                                   metric, metric, metric))\n",
    "\n",
    "        cnn1D_model.train(train_oh, train_weights)\n",
    "        preds, cnn1d_stats = cnn1D_model.test(test_oh)\n",
    "        if num_class == 2:\n",
    "                cnn1d_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=cnn1d_stats[\"AUC\"]\n",
    "        cnn1d_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=cnn1d_stats[\"MCC\"]\n",
    "        cnn1d_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=cnn1d_stats[\"Precision\"]\n",
    "        cnn1d_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=cnn1d_stats[\"Recall\"]\n",
    "        cnn1d_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=cnn1d_stats[\"F1\"]\n",
    "\n",
    "        mlpnn_model.train(train_oh, train_weights)\n",
    "        preds, mlpnn_stats = mlpnn_model.test(test_oh)\n",
    "        if num_class == 2:\n",
    "                mlpnn_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=mlpnn_stats[\"AUC\"]\n",
    "        mlpnn_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=mlpnn_stats[\"MCC\"]\n",
    "        mlpnn_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=mlpnn_stats[\"Precision\"]\n",
    "        mlpnn_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=mlpnn_stats[\"Recall\"]\n",
    "        mlpnn_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=mlpnn_stats[\"F1\"]\n",
    "        \n",
    "        rf_model.train(train)\n",
    "        preds, rf_stats = rf_model.test(test)\n",
    "        if num_class == 2:\n",
    "                rf_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=rf_stats[\"AUC\"]\n",
    "        rf_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=rf_stats[\"MCC\"]\n",
    "        rf_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=rf_stats[\"Precision\"]\n",
    "        rf_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=rf_stats[\"Recall\"]\n",
    "        rf_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=rf_stats[\"F1\"]\n",
    "        \n",
    "        svm_model.train(train)\n",
    "        preds, svm_stats = svm_model.test(test)\n",
    "        if num_class == 2:\n",
    "                svm_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=svm_stats[\"AUC\"]\n",
    "        svm_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=svm_stats[\"MCC\"]\n",
    "        svm_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=svm_stats[\"Precision\"]\n",
    "        svm_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=svm_stats[\"Recall\"]\n",
    "        svm_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=svm_stats[\"F1\"]\n",
    "        \n",
    "        lasso_model.train(train)\n",
    "        preds, lasso_stats = lasso_model.test(test)\n",
    "        if num_class == 2:\n",
    "                lasso_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=lasso_stats[\"AUC\"]\n",
    "        lasso_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=lasso_stats[\"MCC\"]\n",
    "        lasso_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=lasso_stats[\"Precision\"]\n",
    "        lasso_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=lasso_stats[\"Recall\"]\n",
    "        lasso_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=lasso_stats[\"F1\"]\n",
    "        \n",
    "                          \n",
    "        \n",
    "        if metric == \"AUC\":\n",
    "                print(\"# %d\\t%d\\t%.3f\\t\\t%.3f\\t\\t%.3f\\t\\t%.3f\\t\\t%.3f\" % (run, fold, rf_stats[\"AUC\"], svm_stats[\"AUC\"],\n",
    "                                                          lasso_stats[\"AUC\"], mlpnn_stats[\"AUC\"], cnn1d_stats[\"AUC\"]))\n",
    "        if metric == \"MCC\":\n",
    "                print(\"# %d\\t%d\\t%.3f\\t\\t%.3f\\t\\t%.3f\\t\\t%.3f\\t\\t%.3f\" % (run, fold, rf_stats[\"MCC\"], svm_stats[\"MCC\"], \n",
    "                                                          lasso_stats[\"MCC\"], mlpnn_stats[\"MCC\"], cnn1d_stats[\"MCC\"]))\n",
    "\n",
    "        cnn1D_model.destroy()\n",
    "        mlpnn_model.destroy()\n",
    "        del(rf_model)\n",
    "        del(svm_model)\n",
    "        del(lasso_model)\n",
    "        \n",
    "        fold += 1\n",
    "    run += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1d_stat_df.to_csv(results_dir + \"\\cnn1d_raw_evaluation.csv\")\n",
    "mlpnn_stat_df.to_csv(results_dir + \"\\mlpnn_raw_evaluation.csv\")\n",
    "lasso_stat_df.to_csv(results_dir + \"\\lasso_raw_evaluation.csv\")\n",
    "svm_stat_df.to_csv(results_dir + \"\\svm_raw_evaluation.csv\")\n",
    "rf_stat_df.to_csv(results_dir + \"\\rf_raw_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>MLPNN</th>\n",
       "      <th>CNN1D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.935721</td>\n",
       "      <td>0.939319</td>\n",
       "      <td>0.901722</td>\n",
       "      <td>0.923875</td>\n",
       "      <td>0.899237</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.733145</td>\n",
       "      <td>0.756933</td>\n",
       "      <td>0.661780</td>\n",
       "      <td>0.737562</td>\n",
       "      <td>0.663150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.871287</td>\n",
       "      <td>0.881488</td>\n",
       "      <td>0.838383</td>\n",
       "      <td>0.870817</td>\n",
       "      <td>0.840175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.862055</td>\n",
       "      <td>0.875445</td>\n",
       "      <td>0.823600</td>\n",
       "      <td>0.866733</td>\n",
       "      <td>0.823205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.861067</td>\n",
       "      <td>0.874997</td>\n",
       "      <td>0.821580</td>\n",
       "      <td>0.866408</td>\n",
       "      <td>0.821093</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RF       SVM     LASSO     MLPNN     CNN1D\n",
       "AUC        0.935721  0.939319  0.901722  0.923875  0.899237\n",
       "MCC        0.733145  0.756933  0.661780  0.737562  0.663150\n",
       "Precision  0.871287  0.881488  0.838383  0.870817  0.840175\n",
       "Recall     0.862055  0.875445  0.823600  0.866733  0.823205\n",
       "F1         0.861067  0.874997  0.821580  0.866408  0.821093"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], \n",
    "                            columns=[\"RF\", \"SVM\", \"LASSO\", \"MLPNN\", \"CNN1D\"])\n",
    "benchmark_df[\"RF\"] = rf_stat_df.mean(1)\n",
    "benchmark_df[\"SVM\"] = svm_stat_df.mean(1)\n",
    "benchmark_df[\"LASSO\"] = lasso_stat_df.mean(1)\n",
    "benchmark_df[\"MLPNN\"] = mlpnn_stat_df.mean(1)\n",
    "benchmark_df[\"CNN1D\"] = cnn1d_stat_df.mean(1)\n",
    "benchmark_df.to_csv(results_dir + \"\\benchmark_raw.csv\")\n",
    "benchmark_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tree Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CNN-1D\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise (GaussianNois (None, 1, 479, 1)         0         \n",
      "_________________________________________________________________\n",
      "conv_0 (Conv2D)              (None, 1, 470, 32)        352       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 1, 235, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv_1 (Conv2D)              (None, 1, 226, 32)        10272     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 1, 113, 32)        0         \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 3616)              0         \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 3616)              0         \n",
      "_________________________________________________________________\n",
      "fc_0 (Dense)                 (None, 32)                115744    \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 127,490\n",
      "Trainable params: 127,490\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      "MLPNN\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gaussian_noise_1 (GaussianNo (None, 479)               0         \n",
      "_________________________________________________________________\n",
      "fc_0 (Dense)                 (None, 32)                15360     \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "fc_1 (Dense)                 (None, 32)                1056      \n",
      "_________________________________________________________________\n",
      "dropout_4 (Dropout)          (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "output (Dense)               (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 16,482\n",
      "Trainable params: 16,482\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "\n",
      "\n",
      " Run\tFold\tRF AUC\t\tSVM AUC\t\tLASSO AUC\tMLPNN AUC\tCNN-1D AUC\n",
      "# 0\t0\t1.000\t\t0.986\t\t0.896\t\t0.979\t\t0.958\n",
      "# 0\t1\t0.944\t\t0.785\t\t0.819\t\t0.924\t\t0.715\n",
      "# 0\t2\t0.951\t\t0.986\t\t0.924\t\t0.972\t\t0.903\n",
      "# 0\t3\t0.910\t\t0.882\t\t0.917\t\t0.903\t\t0.812\n",
      "# 0\t4\t0.913\t\t0.947\t\t0.871\t\t0.924\t\t0.833\n",
      "# 0\t5\t0.955\t\t0.970\t\t0.917\t\t0.977\t\t0.962\n",
      "# 0\t6\t0.879\t\t0.962\t\t0.917\t\t0.955\t\t0.871\n",
      "# 0\t7\t0.985\t\t0.992\t\t1.000\t\t0.992\t\t1.000\n",
      "# 0\t8\t0.876\t\t0.917\t\t0.926\t\t0.917\t\t0.888\n",
      "# 0\t9\t0.884\t\t0.901\t\t0.826\t\t0.818\t\t0.711\n"
     ]
    }
   ],
   "source": [
    "cnn1d_tree_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "mlpnn_tree_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "rf_tree_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "svm_tree_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "lasso_tree_stat_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], columns=cv_list)\n",
    "\n",
    "run = 0\n",
    "for seed in seeds:\n",
    "    skf = StratifiedKFold(n_splits=num_test, shuffle=True, random_state=seed)\n",
    "    fold = 0\n",
    "    for train_index, test_index in skf.split(my_maps, labels):\n",
    "        train_x, test_x = tree_x[train_index,:], tree_x[test_index,:]\n",
    "        train_y_oh, test_y_oh = labels_oh[train_index,:], labels_oh[test_index,:]\n",
    "        train_y, test_y = labels[train_index], labels[test_index]\n",
    "        \n",
    "        train_x = np.log(train_x + 1)\n",
    "        test_x = np.log(test_x + 1)\n",
    "        \n",
    "        c_prob = [0] * len(np.unique(labels))\n",
    "        train_weights = []\n",
    "\n",
    "        for l in np.unique(labels):\n",
    "            a = float(len(labels))\n",
    "            b = 2.0 * float((np.sum(labels==l)))\n",
    "            c_prob[int(l)] = a/b\n",
    "\n",
    "        c_prob = np.array(c_prob).reshape(-1)\n",
    "\n",
    "        for l in np.argmax(train_y_oh, 1):\n",
    "            train_weights.append(c_prob[int(l)])\n",
    "        train_weights = np.array(train_weights)\n",
    "        \n",
    "        scaler = MinMaxScaler().fit(train_x)\n",
    "        train_x = np.clip(scaler.transform(train_x), 0, 1)\n",
    "        test_x = np.clip(scaler.transform(test_x), 0, 1) \n",
    "\n",
    "        train_oh = [train_x, train_y_oh]\n",
    "        test_oh = [test_x, test_y_oh]\n",
    "\n",
    "        train = [train_x, train_y]\n",
    "        test = [test_x, test_y]\n",
    "        \n",
    "        cnn1D_model = CNN1D(train_x.shape[1], num_class, config)\n",
    "        mlpnn_model = MLPNN(train_x.shape[1], num_class, config)\n",
    "        rf_model = RF(config)\n",
    "        svm_model = SVM(config, label_set)\n",
    "        lasso_model = LASSO(config, label_set)\n",
    "        \n",
    "        if fold + run == 0:\n",
    "            print(\"CNN-1D\")\n",
    "            print(cnn1D_model.model.summary())\n",
    "            print(\"\\n\\nMLPNN\")\n",
    "            print(mlpnn_model.model.summary())\n",
    "            print(\"\\n\\n Run\\tFold\\tRF %s\\t\\tSVM %s\\t\\tLASSO %s\\tMLPNN %s\\tCNN-1D %s\" % (metric, metric, \n",
    "                                                                                   metric, metric, metric))\n",
    "\n",
    "        cnn1D_model.train(train_oh, train_weights)\n",
    "        preds, cnn1d_stats = cnn1D_model.test(test_oh)\n",
    "        if num_class == 2:\n",
    "                cnn1d_tree_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=cnn1d_stats[\"AUC\"]\n",
    "        cnn1d_tree_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=cnn1d_stats[\"MCC\"]\n",
    "        cnn1d_tree_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=cnn1d_stats[\"Precision\"]\n",
    "        cnn1d_tree_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=cnn1d_stats[\"Recall\"]\n",
    "        cnn1d_tree_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=cnn1d_stats[\"F1\"]\n",
    "\n",
    "        mlpnn_model.train(train_oh, train_weights)\n",
    "        preds, mlpnn_stats = mlpnn_model.test(test_oh)\n",
    "        if num_class == 2:\n",
    "                mlpnn_tree_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=mlpnn_stats[\"AUC\"]\n",
    "        mlpnn_tree_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=mlpnn_stats[\"MCC\"]\n",
    "        mlpnn_tree_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=mlpnn_stats[\"Precision\"]\n",
    "        mlpnn_tree_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=mlpnn_stats[\"Recall\"]\n",
    "        mlpnn_tree_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=mlpnn_stats[\"F1\"]\n",
    "        \n",
    "        rf_model.train(train)\n",
    "        preds, rf_stats = rf_model.test(test)\n",
    "        if num_class == 2:\n",
    "                rf_tree_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=rf_stats[\"AUC\"]\n",
    "        rf_tree_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=rf_stats[\"MCC\"]\n",
    "        rf_tree_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=rf_stats[\"Precision\"]\n",
    "        rf_tree_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=rf_stats[\"Recall\"]\n",
    "        rf_tree_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=rf_stats[\"F1\"]\n",
    "        \n",
    "        svm_model.train(train)\n",
    "        preds, svm_stats = svm_model.test(test)\n",
    "        if num_class == 2:\n",
    "                svm_tree_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=svm_stats[\"AUC\"]\n",
    "        svm_tree_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=svm_stats[\"MCC\"]\n",
    "        svm_tree_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=svm_stats[\"Precision\"]\n",
    "        svm_tree_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=svm_stats[\"Recall\"]\n",
    "        svm_tree_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=svm_stats[\"F1\"]\n",
    "        \n",
    "        lasso_model.train(train)\n",
    "        preds, lasso_stats = lasso_model.test(test)\n",
    "        if num_class == 2:\n",
    "                lasso_tree_stat_df.loc[\"AUC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=lasso_stats[\"AUC\"]\n",
    "        lasso_tree_stat_df.loc[\"MCC\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=lasso_stats[\"MCC\"]\n",
    "        lasso_tree_stat_df.loc[\"Precision\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=lasso_stats[\"Precision\"]\n",
    "        lasso_tree_stat_df.loc[\"Recall\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=lasso_stats[\"Recall\"]\n",
    "        lasso_tree_stat_df.loc[\"F1\"][\"Run_\" + str(run) + \"_CV_\" + str(fold)]=lasso_stats[\"F1\"]\n",
    "        \n",
    "                          \n",
    "        \n",
    "        if metric == \"AUC\":\n",
    "                print(\"# %d\\t%d\\t%.3f\\t\\t%.3f\\t\\t%.3f\\t\\t%.3f\\t\\t%.3f\" % (run, fold, rf_stats[\"AUC\"], svm_stats[\"AUC\"],\n",
    "                                                          lasso_stats[\"AUC\"], mlpnn_stats[\"AUC\"], cnn1d_stats[\"AUC\"]))\n",
    "        if metric == \"MCC\":\n",
    "                print(\"# %d\\t%d\\t%.3f\\t\\t%.3f\\t\\t%.3f\\t\\t%.3f\\t\\t%.3f\" % (run, fold, rf_stats[\"MCC\"], svm_stats[\"MCC\"], \n",
    "                                                          lasso_stats[\"MCC\"], mlpnn_stats[\"MCC\"], cnn1d_stats[\"MCC\"]))\n",
    "\n",
    "        cnn1D_model.destroy()\n",
    "        mlpnn_model.destroy()\n",
    "        del(rf_model)\n",
    "        del(svm_model)\n",
    "        del(lasso_model)\n",
    "        \n",
    "        fold += 1\n",
    "    run += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn1d_tree_stat_df.to_csv(results_dir + \"\\cnn1d_tree_evaluation.csv\")\n",
    "mlpnn_tree_stat_df.to_csv(results_dir + \"\\mlpnn_tree_evaluation.csv\")\n",
    "lasso_tree_stat_df.to_csv(results_dir + \"\\lasso_tree_evaluation.csv\")\n",
    "svm_tree_stat_df.to_csv(results_dir + \"\\svm_tree_evaluation.csv\")\n",
    "rf_tree_stat_df.to_csv(results_dir + \"\\rf_tree_evaluation.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "      <th>LASSO</th>\n",
       "      <th>MLPNN</th>\n",
       "      <th>CNN1D</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AUC</th>\n",
       "      <td>0.929695</td>\n",
       "      <td>0.932828</td>\n",
       "      <td>0.901217</td>\n",
       "      <td>0.936180</td>\n",
       "      <td>0.865473</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MCC</th>\n",
       "      <td>0.759823</td>\n",
       "      <td>0.700783</td>\n",
       "      <td>0.679982</td>\n",
       "      <td>0.734445</td>\n",
       "      <td>0.625129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Precision</th>\n",
       "      <td>0.885077</td>\n",
       "      <td>0.855202</td>\n",
       "      <td>0.852435</td>\n",
       "      <td>0.872013</td>\n",
       "      <td>0.819611</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Recall</th>\n",
       "      <td>0.874918</td>\n",
       "      <td>0.845916</td>\n",
       "      <td>0.828343</td>\n",
       "      <td>0.862582</td>\n",
       "      <td>0.806159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1</th>\n",
       "      <td>0.873893</td>\n",
       "      <td>0.843917</td>\n",
       "      <td>0.824735</td>\n",
       "      <td>0.861618</td>\n",
       "      <td>0.803022</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 RF       SVM     LASSO     MLPNN     CNN1D\n",
       "AUC        0.929695  0.932828  0.901217  0.936180  0.865473\n",
       "MCC        0.759823  0.700783  0.679982  0.734445  0.625129\n",
       "Precision  0.885077  0.855202  0.852435  0.872013  0.819611\n",
       "Recall     0.874918  0.845916  0.828343  0.862582  0.806159\n",
       "F1         0.873893  0.843917  0.824735  0.861618  0.803022"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_tree_df = pd.DataFrame(index=[\"AUC\", \"MCC\", \"Precision\", \"Recall\", \"F1\"], \n",
    "                            columns=[\"RF\", \"SVM\", \"LASSO\", \"MLPNN\", \"CNN1D\"])\n",
    "benchmark_tree_df[\"RF\"] = rf_tree_stat_df.mean(1)\n",
    "benchmark_tree_df[\"SVM\"] = svm_tree_stat_df.mean(1)\n",
    "benchmark_tree_df[\"LASSO\"] = lasso_tree_stat_df.mean(1)\n",
    "benchmark_tree_df[\"MLPNN\"] = mlpnn_tree_stat_df.mean(1)\n",
    "benchmark_tree_df[\"CNN1D\"] = cnn1d_tree_stat_df.mean(1)\n",
    "benchmark_tree_df.to_csv(results_dir + \"\\benchmark_tree.csv\")\n",
    "benchmark_tree_df"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:meta-signer2] *",
   "language": "python",
   "name": "conda-env-meta-signer2-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
